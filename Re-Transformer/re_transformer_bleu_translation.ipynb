{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 12688285,
          "sourceType": "datasetVersion",
          "datasetId": 8018252
        },
        {
          "sourceId": 12732100,
          "sourceType": "datasetVersion",
          "datasetId": 8030370
        },
        {
          "sourceId": 12740598,
          "sourceType": "datasetVersion",
          "datasetId": 8053578
        },
        {
          "sourceId": 12740602,
          "sourceType": "datasetVersion",
          "datasetId": 8053581
        },
        {
          "sourceId": 12756926,
          "sourceType": "datasetVersion",
          "datasetId": 8053633
        },
        {
          "sourceId": 12760834,
          "sourceType": "datasetVersion",
          "datasetId": 8047748
        }
      ],
      "dockerImageVersionId": 31090,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Thư viện cần thiết"
      ],
      "metadata": {
        "id": "DaXMNOwjruJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import math"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-14T06:26:15.781887Z",
          "iopub.execute_input": "2025-08-14T06:26:15.782123Z",
          "iopub.status.idle": "2025-08-14T06:26:22.581558Z",
          "shell.execute_reply.started": "2025-08-14T06:26:15.782097Z",
          "shell.execute_reply": "2025-08-14T06:26:22.580985Z"
        },
        "id": "BsBJhkcUWsa0"
      },
      "outputs": [],
      "execution_count": 45
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Đọc dữ liệu từ tệp txt"
      ],
      "metadata": {
        "id": "tYaWj5QEryaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "en_train_file = '/content/drive/MyDrive/Released Corpus/train.en.txt'\n",
        "vi_train_file = '/content/drive/MyDrive/Released Corpus/train.vi.txt'\n",
        "\n",
        "# Read lines\n",
        "with open(en_train_file, 'r', encoding='utf-8') as f_train_en:\n",
        "    en_train_lines = [line.strip() for line in f_train_en.readlines()]\n",
        "\n",
        "with open(vi_train_file, 'r', encoding='utf-8') as f_train_vi:\n",
        "    vi_train_lines = [line.strip() for line in f_train_vi.readlines()]\n",
        "\n",
        "# Check whether length of en_train equal to length of vi_train\n",
        "assert len(en_train_lines) == len(vi_train_lines)\n",
        "\n",
        "train = pd.DataFrame({'en': en_train_lines, 'vi': vi_train_lines})"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-14T06:26:22.587191Z",
          "iopub.execute_input": "2025-08-14T06:26:22.587443Z",
          "iopub.status.idle": "2025-08-14T06:26:26.732314Z",
          "shell.execute_reply.started": "2025-08-14T06:26:22.587420Z",
          "shell.execute_reply": "2025-08-14T06:26:26.731759Z"
        },
        "id": "lHxNjOAbWsa3"
      },
      "outputs": [],
      "execution_count": 47
    },
    {
      "cell_type": "code",
      "source": [
        "en_test_file = '/content/drive/MyDrive/Released Corpus/test.en.txt'\n",
        "vi_test_file = '/content/drive/MyDrive/Released Corpus/test.vi.txt'\n",
        "\n",
        "# Read lines\n",
        "with open(en_test_file, 'r', encoding='utf-8') as f_test_en:\n",
        "    en_test_lines = [line.strip() for line in f_test_en.readlines()]\n",
        "\n",
        "with open(vi_test_file, 'r', encoding='utf-8') as f_test_vi:\n",
        "    vi_test_lines = [line.strip() for line in f_test_vi.readlines()]\n",
        "\n",
        "# Check whether length of en_train equal to length of vi_train\n",
        "assert len(en_test_lines) == len(vi_test_lines)\n",
        "\n",
        "test = pd.DataFrame({'en': en_test_lines, 'vi': vi_test_lines})"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-14T06:26:26.733030Z",
          "iopub.execute_input": "2025-08-14T06:26:26.733236Z",
          "iopub.status.idle": "2025-08-14T06:26:26.793176Z",
          "shell.execute_reply.started": "2025-08-14T06:26:26.733218Z",
          "shell.execute_reply": "2025-08-14T06:26:26.792707Z"
        },
        "id": "3HVo_fhfWsa3"
      },
      "outputs": [],
      "execution_count": 48
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-14T06:26:26.793812Z",
          "iopub.execute_input": "2025-08-14T06:26:26.794004Z",
          "iopub.status.idle": "2025-08-14T06:26:26.849692Z",
          "shell.execute_reply.started": "2025-08-14T06:26:26.793989Z",
          "shell.execute_reply": "2025-08-14T06:26:26.849007Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "4gRgeyxSWsa4",
        "outputId": "04f68c96-8520-441c-d4b1-513746167f25"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                       en  \\\n",
              "0       To evaluate clinical, subclinical symptoms of ...   \n",
              "1       Evaluate clinical, subclinical symptoms of pat...   \n",
              "2       There was a relation between vasodilatation an...   \n",
              "3       Otittis media effusion on V a is a common dise...   \n",
              "4       Main symptoms are rhinitis, nasal congestion, ...   \n",
              "...                                                   ...   \n",
              "499995  Patients and methods: Over-40-year-old men are...   \n",
              "499996  If chronic, the age at onset (eg, since birth,...   \n",
              "499997  Equipment for Removing a Tick Cleansing soluti...   \n",
              "499998                            Normal sigmoid at TVUS.   \n",
              "499999  Method: 19 patients underwent 25 coronectomy p...   \n",
              "\n",
              "                                                       vi  \n",
              "0       Nghiên cứu đặc điểm lâm sàng, cận lâm sàng bện...  \n",
              "1       Đánh giá đặc điểm lâm sàng, cận lâm sàng bệnh ...  \n",
              "2       Có sự liên quan giữa độ quá phát V.a với mức đ...  \n",
              "3       Kết luận: Viêm tai ứ dịch trên viêm V.a là bện...  \n",
              "4       Triệu chứng cơ năng nổi bật là chảy mũi, ngạt ...  \n",
              "...                                                   ...  \n",
              "499995  Đối tượng và phương pháp nghiên cứu: Nam giới ...  \n",
              "499996  Nếu mạn tính, cần xác định thời điểm xuất hiện...  \n",
              "499997  Thiết bị dùng để lấy bọ ve Dung dịch rửa như d...  \n",
              "499998  Đại tràng Sigma bình thưởng trên Siêu âm qua n...  \n",
              "499999  Đối tượng - Phương pháp nghiên cứu: Nghiên cứu...  \n",
              "\n",
              "[500000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-36c8d490-b87e-4349-98c1-9cae72c4dae1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>vi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>To evaluate clinical, subclinical symptoms of ...</td>\n",
              "      <td>Nghiên cứu đặc điểm lâm sàng, cận lâm sàng bện...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Evaluate clinical, subclinical symptoms of pat...</td>\n",
              "      <td>Đánh giá đặc điểm lâm sàng, cận lâm sàng bệnh ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>There was a relation between vasodilatation an...</td>\n",
              "      <td>Có sự liên quan giữa độ quá phát V.a với mức đ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Otittis media effusion on V a is a common dise...</td>\n",
              "      <td>Kết luận: Viêm tai ứ dịch trên viêm V.a là bện...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Main symptoms are rhinitis, nasal congestion, ...</td>\n",
              "      <td>Triệu chứng cơ năng nổi bật là chảy mũi, ngạt ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499995</th>\n",
              "      <td>Patients and methods: Over-40-year-old men are...</td>\n",
              "      <td>Đối tượng và phương pháp nghiên cứu: Nam giới ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499996</th>\n",
              "      <td>If chronic, the age at onset (eg, since birth,...</td>\n",
              "      <td>Nếu mạn tính, cần xác định thời điểm xuất hiện...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499997</th>\n",
              "      <td>Equipment for Removing a Tick Cleansing soluti...</td>\n",
              "      <td>Thiết bị dùng để lấy bọ ve Dung dịch rửa như d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499998</th>\n",
              "      <td>Normal sigmoid at TVUS.</td>\n",
              "      <td>Đại tràng Sigma bình thưởng trên Siêu âm qua n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499999</th>\n",
              "      <td>Method: 19 patients underwent 25 coronectomy p...</td>\n",
              "      <td>Đối tượng - Phương pháp nghiên cứu: Nghiên cứu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500000 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-36c8d490-b87e-4349-98c1-9cae72c4dae1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-36c8d490-b87e-4349-98c1-9cae72c4dae1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-36c8d490-b87e-4349-98c1-9cae72c4dae1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-92a41e69-30a6-487b-9cde-eef5eb385b1e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-92a41e69-30a6-487b-9cde-eef5eb385b1e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-92a41e69-30a6-487b-9cde-eef5eb385b1e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_7673ac05-a617-49d6-999f-21edd7c99e14\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_7673ac05-a617-49d6-999f-21edd7c99e14 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('train');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "execution_count": 49
    },
    {
      "cell_type": "code",
      "source": [
        "test"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-14T06:26:26.850484Z",
          "iopub.execute_input": "2025-08-14T06:26:26.850716Z",
          "iopub.status.idle": "2025-08-14T06:26:26.858206Z",
          "shell.execute_reply.started": "2025-08-14T06:26:26.850683Z",
          "shell.execute_reply": "2025-08-14T06:26:26.857705Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "eM2WlEy9Wsa4",
        "outputId": "708089b6-259f-4e60-96c4-9b990768865a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     en  \\\n",
              "0     Knowledge, practices in public health service ...   \n",
              "1     Describe knowledge, practices in public health...   \n",
              "2     Methodology: A cross sectional study was used ...   \n",
              "3     Results: Percentage of card's holders who knew...   \n",
              "4     Percentage of card's holders who went to the f...   \n",
              "...                                                 ...   \n",
              "2995  Therefore, we conduct research to evaluate the...   \n",
              "2996  Methods: A cross-sectional descriptive study w...   \n",
              "2997  Results: In 169 patients, 23.1% and 19.5% pati...   \n",
              "2998  Self-tanning products do not provide significa...   \n",
              "2999  Benzathine penicillin G is a long-acting formu...   \n",
              "\n",
              "                                                     vi  \n",
              "0     Thực trạng kiến thức và thực hành của người có...  \n",
              "1     Mô tả thực trạng kiến thức, thực hành của ngườ...  \n",
              "2     Phương pháp: Thiết kế nghiên mô tả cắt ngang đ...  \n",
              "3     Kết quả: Tỷ lệ người biết được khám chữa bệnh ...  \n",
              "4     Tỷ lệ người có thẻ BHYT thực hành khám chữa bệ...  \n",
              "...                                                 ...  \n",
              "2995  Chính vì vậy chúng tôi tiến hành nghiên cứu đá...  \n",
              "2996  Phương pháp nghiên cứu: Nghiên cứu mô tả cắt n...  \n",
              "2997  Số lượng bệnh nhân bị di căn hạch rốn phổi cao...  \n",
              "2998  Các sản phẩm tự tạo màu da không có khả năng b...  \n",
              "2999  Benzathine penicillin G là một dạng thuốc có t...  \n",
              "\n",
              "[3000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-199fd9de-6b74-40c2-a019-2612a5da8933\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>vi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Knowledge, practices in public health service ...</td>\n",
              "      <td>Thực trạng kiến thức và thực hành của người có...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Describe knowledge, practices in public health...</td>\n",
              "      <td>Mô tả thực trạng kiến thức, thực hành của ngườ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Methodology: A cross sectional study was used ...</td>\n",
              "      <td>Phương pháp: Thiết kế nghiên mô tả cắt ngang đ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Results: Percentage of card's holders who knew...</td>\n",
              "      <td>Kết quả: Tỷ lệ người biết được khám chữa bệnh ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Percentage of card's holders who went to the f...</td>\n",
              "      <td>Tỷ lệ người có thẻ BHYT thực hành khám chữa bệ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2995</th>\n",
              "      <td>Therefore, we conduct research to evaluate the...</td>\n",
              "      <td>Chính vì vậy chúng tôi tiến hành nghiên cứu đá...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2996</th>\n",
              "      <td>Methods: A cross-sectional descriptive study w...</td>\n",
              "      <td>Phương pháp nghiên cứu: Nghiên cứu mô tả cắt n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2997</th>\n",
              "      <td>Results: In 169 patients, 23.1% and 19.5% pati...</td>\n",
              "      <td>Số lượng bệnh nhân bị di căn hạch rốn phổi cao...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2998</th>\n",
              "      <td>Self-tanning products do not provide significa...</td>\n",
              "      <td>Các sản phẩm tự tạo màu da không có khả năng b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2999</th>\n",
              "      <td>Benzathine penicillin G is a long-acting formu...</td>\n",
              "      <td>Benzathine penicillin G là một dạng thuốc có t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3000 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-199fd9de-6b74-40c2-a019-2612a5da8933')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-199fd9de-6b74-40c2-a019-2612a5da8933 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-199fd9de-6b74-40c2-a019-2612a5da8933');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-eca196a5-0bb1-46f0-aed3-7dc9fc9e2e90\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-eca196a5-0bb1-46f0-aed3-7dc9fc9e2e90')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-eca196a5-0bb1-46f0-aed3-7dc9fc9e2e90 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_770406cf-d1a6-4ecc-a88c-ccf8e6a78c65\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('test')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_770406cf-d1a6-4ecc-a88c-ccf8e6a78c65 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('test');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test",
              "summary": "{\n  \"name\": \"test\",\n  \"rows\": 3000,\n  \"fields\": [\n    {\n      \"column\": \"en\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2997,\n        \"samples\": [\n          \"Objective: To determine the proportion of anxiety, depression and the association with the duration of taking oral isotretinoin in patients with acne at Hospital of Dermato-Venereology, Ho Chi Minh city.\",\n          \"Subjects and methods: Clinical research, randomized controlled trials (RCTs) of 120 patients with post-herpetic neuralgia at National Hospital of Dermatology and Venereology from July 2020 to May 2021.Results: Mean age of research and control group were 66.43 \\u00b1 8.67 and 66, 57 \\u00b1 8, 66, repecstively.\",\n          \"Conclusion: Our study has shown that the percutaneous closure of large secondary atrial septal defects in the 20 - 37 mm diameter range under intracardiac echocardiography guidance can be performed safely and effectively.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vi\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2995,\n        \"samples\": [\n          \"T\\u1eeb kho\\u00e1: C\\u1ea3i ti\\u1ebfn, hi\\u1ec3u bi\\u1ebft, ng\\u01b0\\u1eddi b\\u1ec7nh v\\u00e0 gia \\u0111\\u00ecnh, ch\\u0103m s\\u00f3c.\",\n          \"Vi\\u1ec7c n\\u00e0y c\\u00f3 th\\u1ec3 \\u0111\\u01b0\\u1ee3c th\\u1ef1c hi\\u1ec7n t\\u1ea1i ph\\u00f2ng c\\u1ea5p c\\u1ee9u ho\\u1eb7c ph\\u00f2ng kh\\u00e1m ngo\\u1ea1i tr\\u00fa.\",\n          \"\\u0110\\u00e1nh gi\\u00e1 c\\u00e1c y\\u1ebfu t\\u1ed1 ti\\u00ean l\\u01b0\\u1ee3ng th\\u00e0nh c\\u00f4ng c\\u1ee7a k\\u1ef9 thu\\u1eadt th\\u1edf oxy l\\u00e0m \\u1ea9m d\\u00f2ng cao qua canuyn m\\u0169i (HHFNC) tr\\u00ean b\\u1ec7nh nh\\u00e2n \\u0111\\u1ee3t c\\u1ea5p b\\u1ec7nh ph\\u1ed5i t\\u1eafc ngh\\u1ebdn m\\u1ea1n t\\u00ednh (COPD).\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "execution_count": 50
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hàm tiền xử lý dữ liệu cho cả văn bản tiếng Anh và tiếng Việt"
      ],
      "metadata": {
        "id": "baE6kWuor4Yy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def english_preprocessing(text):\n",
        "    # Chuyển chữ hoa thành chữ thường\n",
        "    text = text.lower()\n",
        "\n",
        "    # Chuẩn hóa khoảng trắng ban đầu\n",
        "    text = re.sub(r'\\s+', ' ', text.strip())\n",
        "\n",
        "    # Tách dấu hai chấm nếu dính liền (e.g., methods:This → methods: This)\n",
        "    text = re.sub(r'(?<=\\w):(?=\\w)', ': ', text)\n",
        "\n",
        "    # Xóa dấu ngoặc kép không cần thiết, nhưng giữ lại dấu nháy đơn trong từ (e.g., it's, don't)\n",
        "    text = re.sub(r'[“”\\\"`]', '', text)\n",
        "\n",
        "    # Xử lý đơn vị viết dính (e.g., 25ui/l → 25 ui/l)\n",
        "    text = re.sub(r'(\\d+)\\s*([a-zA-Z]+)', r'\\1 \\2', text)\n",
        "\n",
        "    # Chuẩn hóa số: \"81, 3%\" → \"81.3%\", \"9, 001\" → \"9001\"\n",
        "    text = re.sub(r'(\\d),\\s*(\\d)', r'\\1.\\2', text)  # 81, 3 → 81.3\n",
        "    text = re.sub(r'(?<=\\d)\\s*,\\s*(?=\\d)', '', text)  # 9, 001 → 9001\n",
        "\n",
        "    # Chuẩn hóa các loại dash\n",
        "    text = re.sub(r'[–—−]', '-', text)\n",
        "\n",
        "    # Giữ lại định dạng đúng cho các ký hiệu y học\n",
        "    text = re.sub(r'\\s*/\\s*', '/', text)   # PET / CT → PET/CT\n",
        "    text = re.sub(r'\\s*\\+\\s*', '+', text)  # ( + ) → (+)\n",
        "\n",
        "    # Thêm khoảng trắng quanh toán tử\n",
        "    text = re.sub(r'\\s*(<=|>=|=|≠|±|<|>)\\s*', r' \\1 ', text)\n",
        "\n",
        "    # Tách số và dấu %\n",
        "    text = re.sub(r'(\\d+(\\.\\d+)?)%', r'\\1 %', text)\n",
        "\n",
        "    # Làm sạch cuối cùng\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-14T06:26:27.579987Z",
          "iopub.execute_input": "2025-08-14T06:26:27.580291Z",
          "iopub.status.idle": "2025-08-14T06:26:27.595357Z",
          "shell.execute_reply.started": "2025-08-14T06:26:27.580274Z",
          "shell.execute_reply": "2025-08-14T06:26:27.594704Z"
        },
        "id": "yOBwfKlpWsa6"
      },
      "outputs": [],
      "execution_count": 51
    },
    {
      "cell_type": "code",
      "source": [
        "def vietnamese_preprocessing(text):\n",
        "    # Chuyển chữ hoa thành chữ thường\n",
        "    text = text.lower()\n",
        "\n",
        "    # Chuẩn hóa khoảng trắng ban đầu\n",
        "    text = re.sub(r'\\s+', ' ', text.strip())\n",
        "\n",
        "    # Tách dấu hai chấm nếu dính liền (e.g., methods:This → methods: This)\n",
        "    text = re.sub(r'(?<=\\w):(?=\\w)', ': ', text)\n",
        "\n",
        "    # Loại bỏ dấu câu không cần thiết\n",
        "    text = re.sub(r'[“”\\\"\\'`]', '', text)\n",
        "\n",
        "    # Xử lý đơn vị viết dính (e.g., 25ui/l → 25 ui/l)\n",
        "    text = re.sub(r'(\\d+)\\s*([a-zA-Z]+)', r'\\1 \\2', text)\n",
        "\n",
        "    # Chuẩn hóa số: \"81, 3%\" → \"81.3%\", \"9, 001\" → \"9001\"\n",
        "    text = re.sub(r'(\\d),\\s*(\\d)', r'\\1.\\2', text)  # 81, 3 → 81.3\n",
        "    text = re.sub(r'(?<=\\d)\\s*,\\s*(?=\\d)', '', text)  # 9, 001 → 9001\n",
        "\n",
        "    # Chuẩn hóa các loại dash\n",
        "    text = re.sub(r'[–—−]', '-', text)\n",
        "\n",
        "    # Giữ lại định dạng đúng cho các ký hiệu y học\n",
        "    text = re.sub(r'\\s*/\\s*', '/', text)   # PET / CT → PET/CT\n",
        "    text = re.sub(r'\\s*\\+\\s*', '+', text)  # ( + ) → (+)\n",
        "\n",
        "    # Thêm khoảng trắng quanh toán tử\n",
        "    text = re.sub(r'\\s*(<=|>=|=|≠|±|<|>)\\s*', r' \\1 ', text)\n",
        "\n",
        "    # Tách số và dấu %\n",
        "    text = re.sub(r'(\\d+(\\.\\d+)?)%', r'\\1 %', text)\n",
        "\n",
        "    # Làm sạch cuối cùng\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-14T06:26:27.595996Z",
          "iopub.execute_input": "2025-08-14T06:26:27.596202Z",
          "iopub.status.idle": "2025-08-14T06:26:27.608698Z",
          "shell.execute_reply.started": "2025-08-14T06:26:27.596187Z",
          "shell.execute_reply": "2025-08-14T06:26:27.608190Z"
        },
        "id": "EycY07DPWsa6"
      },
      "outputs": [],
      "execution_count": 52
    },
    {
      "cell_type": "code",
      "source": [
        "# Tiền xử lý dữ liệu đối với tập train và tập test\n",
        "train['en'] = train['en'].apply(english_preprocessing)\n",
        "train['vi'] = train['vi'].apply(vietnamese_preprocessing)\n",
        "\n",
        "test['en'] = test['en'].apply(english_preprocessing)\n",
        "test['vi'] = test['vi'].apply(vietnamese_preprocessing)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-14T06:26:27.609306Z",
          "iopub.execute_input": "2025-08-14T06:26:27.609499Z",
          "iopub.status.idle": "2025-08-14T06:27:31.741858Z",
          "shell.execute_reply.started": "2025-08-14T06:26:27.609485Z",
          "shell.execute_reply": "2025-08-14T06:27:31.741326Z"
        },
        "id": "v-zf812HWsa6"
      },
      "outputs": [],
      "execution_count": 53
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizers import Tokenizer\n",
        "tokenizer_en = Tokenizer.from_file(\"/content/drive/MyDrive/Released Corpus/tokenizer_en.json\")\n",
        "tokenizer_vi = Tokenizer.from_file(\"/content/drive/MyDrive/Released Corpus/tokenizer_vi.json\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-14T06:27:31.742545Z",
          "iopub.execute_input": "2025-08-14T06:27:31.742745Z",
          "iopub.status.idle": "2025-08-14T06:27:32.084413Z",
          "shell.execute_reply.started": "2025-08-14T06:27:31.742728Z",
          "shell.execute_reply": "2025-08-14T06:27:32.083809Z"
        },
        "id": "G7y0reY4Wsa7"
      },
      "outputs": [],
      "execution_count": 54
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 256  # giới hạn chiều dài token sequence\n",
        "\n",
        "def encode_dataset(df, tokenizer_en, tokenizer_vi):\n",
        "    bos_en = tokenizer_en.token_to_id(\"<s>\")\n",
        "    eos_en = tokenizer_en.token_to_id(\"</s>\")\n",
        "    bos_vi = tokenizer_vi.token_to_id(\"<s>\")\n",
        "    eos_vi = tokenizer_vi.token_to_id(\"</s>\")\n",
        "\n",
        "    def truncate(seq, max_len):\n",
        "        return seq[:max_len] if len(seq) > max_len else seq\n",
        "\n",
        "    def encode_pair(en_text, vi_text):\n",
        "        # Encode English\n",
        "        en_ids = tokenizer_en.encode(en_text).ids\n",
        "        en_ids = truncate(en_ids, MAX_LEN - 2)  # trừ 2 vì thêm <s> và </s>\n",
        "        en_input = [bos_en] + en_ids + [eos_en]\n",
        "\n",
        "        # Encode Vietnamese (một lần)\n",
        "        vi_ids = tokenizer_vi.encode(vi_text).ids\n",
        "        vi_ids = truncate(vi_ids, MAX_LEN - 2)  # trừ 2 vì thêm <s> và </s>\n",
        "        vi_full = [bos_vi] + vi_ids + [eos_vi]\n",
        "\n",
        "        # Tách ra:\n",
        "        vi_input = vi_full[:-1]  # bỏ </s>\n",
        "        vi_target = vi_full[1:]  # bỏ <s>\n",
        "\n",
        "        return en_input, vi_input, vi_target\n",
        "\n",
        "    encoded = df.apply(lambda row: encode_pair(row['en'], row['vi']), axis=1)\n",
        "    en_input, vi_input, vi_target = zip(*encoded)\n",
        "\n",
        "    return pd.DataFrame({\n",
        "        'en_input': en_input,\n",
        "        'vi_input': vi_input,\n",
        "        'vi_target': vi_target\n",
        "    })"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-14T06:27:32.085054Z",
          "iopub.execute_input": "2025-08-14T06:27:32.085261Z",
          "iopub.status.idle": "2025-08-14T06:27:32.092100Z",
          "shell.execute_reply.started": "2025-08-14T06:27:32.085244Z",
          "shell.execute_reply": "2025-08-14T06:27:32.091257Z"
        },
        "id": "K9wqsFYeWsa7"
      },
      "outputs": [],
      "execution_count": 55
    },
    {
      "cell_type": "code",
      "source": [
        "train_encoded = encode_dataset(train, tokenizer_en, tokenizer_vi)\n",
        "test_encoded = encode_dataset(test, tokenizer_en, tokenizer_vi)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-14T06:27:32.092889Z",
          "iopub.execute_input": "2025-08-14T06:27:32.093189Z",
          "iopub.status.idle": "2025-08-14T06:29:22.311599Z",
          "shell.execute_reply.started": "2025-08-14T06:27:32.093160Z",
          "shell.execute_reply": "2025-08-14T06:29:22.310943Z"
        },
        "id": "bJsY4IDxWsa7"
      },
      "outputs": [],
      "execution_count": 56
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer architecture"
      ],
      "metadata": {
        "id": "na_nyPPpWsa7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class InputEmbeddings(nn.Module):\n",
        "  def __init__(self, d_model: int, vocab_size: int):\n",
        "    super(InputEmbeddings, self).__init__()\n",
        "    self.d_model = d_model\n",
        "    self.vocab_size = vocab_size\n",
        "    self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # (batch, seq_len) --> (batch, seq_len, d_model)\n",
        "    # Multiply by sqrt(d_model) to scale the embeddings according to the paper\n",
        "    return self.embedding(x) * math.sqrt(self.d_model)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-14T06:29:22.312320Z",
          "iopub.execute_input": "2025-08-14T06:29:22.312580Z",
          "iopub.status.idle": "2025-08-14T06:29:22.317302Z",
          "shell.execute_reply.started": "2025-08-14T06:29:22.312558Z",
          "shell.execute_reply": "2025-08-14T06:29:22.316537Z"
        },
        "id": "dihzq1DIWsa8"
      },
      "outputs": [],
      "execution_count": 57
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "  def __init__(self, d_model: int, seq_len: int, dropout: float):\n",
        "    super().__init__()\n",
        "    self.d_model = d_model\n",
        "    self.seq_len = seq_len\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    # Create a matrix of shape (seq_len, d_model)\n",
        "    pe = torch.zeros(seq_len, d_model)\n",
        "    # Create a vector of shape (seq_len)\n",
        "    position = torch.arange(0, seq_len, dtype=torch.float).unsqueeze(1) # (seq_len, 1)\n",
        "    # Create a vector of shape (d_model)\n",
        "    div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)) # (d_model / 2)\n",
        "    # Apply sine to even indices\n",
        "    pe[:, 0::2] = torch.sin(position * div_term) # sin(position * (10000 ** (2i / d_model))\n",
        "    # Apply cosine to odd indices\n",
        "    pe[:, 1::2] = torch.cos(position * div_term) # cos(position * (10000 ** (2i / d_model))\n",
        "    # Add a batch dimension to the positional encoding\n",
        "    pe = pe.unsqueeze(0) # (1, seq_len, d_model)\n",
        "    # Register the positional encoding as a buffer\n",
        "    self.register_buffer('pe', pe)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x + (self.pe[:, :x.shape[1], :]).requires_grad_(False) # (batch, seq_len, d_model)\n",
        "    return self.dropout(x)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-14T06:29:22.318244Z",
          "iopub.execute_input": "2025-08-14T06:29:22.319013Z",
          "iopub.status.idle": "2025-08-14T06:29:22.339358Z",
          "shell.execute_reply.started": "2025-08-14T06:29:22.318981Z",
          "shell.execute_reply": "2025-08-14T06:29:22.338717Z"
        },
        "id": "WKGacjWrWsa8"
      },
      "outputs": [],
      "execution_count": 58
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttentionBlock(nn.Module):\n",
        "  def __init__(self, d_model: int, h: int, dropout: float):\n",
        "    super().__init__()\n",
        "    self.d_model = d_model # Embedding vector size\n",
        "    self.h = h # Number of heads\n",
        "\n",
        "    self.d_k = d_model // h # Dimension of vector seen by each head\n",
        "    self.w_q = nn.Linear(d_model, d_model, bias=False) # Wq\n",
        "    self.w_k = nn.Linear(d_model, d_model, bias=False) # Wk\n",
        "    self.w_v = nn.Linear(d_model, d_model, bias=False) # Wv\n",
        "    self.w_o = nn.Linear(d_model, d_model, bias=False) # Wo\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  @staticmethod\n",
        "  def attention(query, key, value, mask, dropout: nn.Dropout):\n",
        "    d_k = query.shape[-1]\n",
        "\n",
        "    # (batch, h, seq_len, d_k) --> (batch, h, seq_len, seq_len)\n",
        "    attention_scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n",
        "    if mask is not None:\n",
        "      # Write a very low value (indicating -inf) to the positions where mask == 0\n",
        "      attention_scores = attention_scores.masked_fill(mask == 0, torch.finfo(attention_scores.dtype).min)\n",
        "\n",
        "    attention_scores = attention_scores.softmax(dim=-1) # (batch, h, seq_len, seq_len) # Apply softmax\n",
        "    if dropout is not None:\n",
        "      attention_scores = dropout(attention_scores)\n",
        "    return torch.matmul(attention_scores, value), attention_scores\n",
        "\n",
        "  def forward(self, q, k, v, mask):\n",
        "    # q, k, v: (batch, seq_len, d_model)\n",
        "    # mask: (batch, seq_len, seq_len)\n",
        "    query = self.w_q(q)\n",
        "    key = self.w_k(k)\n",
        "    value = self.w_v(v)\n",
        "\n",
        "    # (batch, seq_len, d_model) --> (batch, seq_len, h, d_k) --> (batch, h, seq_len, d_k)\n",
        "    query = query.view(query.shape[0], query.shape[1], self.h, self.d_k).transpose(1, 2)\n",
        "    key = key.view(key.shape[0], key.shape[1], self.h, self.d_k).transpose(1, 2)\n",
        "    value = value.view(value.shape[0], value.shape[1], self.h, self.d_k).transpose(1, 2)\n",
        "\n",
        "    # Calculate attention using function we will define next\n",
        "    x, self.attention_scores = MultiHeadAttentionBlock.attention(query, key, value, mask, self.dropout)\n",
        "\n",
        "    # Combine all the heads together\n",
        "    # (batch, h, seq_len, d_k) --> (batch, seq_len, h, d_k) --> (batch, seq_len, d_model)\n",
        "    x = x.transpose(1, 2).contiguous().view(x.shape[0], -1, self.h * self.d_k)\n",
        "\n",
        "    # Apply one final linear transformation\n",
        "    return self.w_o(x)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-14T06:29:22.340062Z",
          "iopub.execute_input": "2025-08-14T06:29:22.340231Z",
          "iopub.status.idle": "2025-08-14T06:29:22.358800Z",
          "shell.execute_reply.started": "2025-08-14T06:29:22.340217Z",
          "shell.execute_reply": "2025-08-14T06:29:22.358018Z"
        },
        "id": "AHFhEcgYWsa8"
      },
      "outputs": [],
      "execution_count": 59
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForwardBlock(nn.Module):\n",
        "  def __init__(self, d_model: int, d_ff: int, dropout: float):\n",
        "    super().__init__()\n",
        "    self.linear_1 = nn.Linear(d_model, d_ff)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.linear_2 = nn.Linear(d_ff, d_model)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # (batch, seq_len, d_model) --> (batch, seq_len, d_ff) --> (batch, seq_len, d_model)\n",
        "    return self.linear_2(self.dropout(torch.relu(self.linear_1(x))))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-14T06:29:22.359535Z",
          "iopub.execute_input": "2025-08-14T06:29:22.359850Z",
          "iopub.status.idle": "2025-08-14T06:29:22.378951Z",
          "shell.execute_reply.started": "2025-08-14T06:29:22.359830Z",
          "shell.execute_reply": "2025-08-14T06:29:22.378336Z"
        },
        "id": "rfX7ZZZMWsa9"
      },
      "outputs": [],
      "execution_count": 60
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualConnection(nn.Module):\n",
        "  def __init__(self, features: int, dropout: float):\n",
        "    super().__init__()\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.norm = nn.LayerNorm(features)\n",
        "\n",
        "  def forward(self, x, sublayer):\n",
        "    # Apply residual connection\n",
        "    return x + self.dropout(sublayer(self.norm(x)))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-14T06:29:22.379642Z",
          "iopub.execute_input": "2025-08-14T06:29:22.379894Z",
          "iopub.status.idle": "2025-08-14T06:29:22.396490Z",
          "shell.execute_reply.started": "2025-08-14T06:29:22.379871Z",
          "shell.execute_reply": "2025-08-14T06:29:22.395923Z"
        },
        "id": "k16eGWtbWsa9"
      },
      "outputs": [],
      "execution_count": 61
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, features: int,\n",
        "                 self_attention_block1: MultiHeadAttentionBlock,\n",
        "                 self_attention_block2: MultiHeadAttentionBlock,\n",
        "                 feed_forward_block: FeedForwardBlock,\n",
        "                 dropout: float):\n",
        "        super().__init__()\n",
        "        self.self_attention_block1 = self_attention_block1\n",
        "        self.self_attention_block2 = self_attention_block2\n",
        "        self.feed_forward_block = feed_forward_block\n",
        "        # 3 residual connections: SA1, SA2, FFN\n",
        "        self.residual_connections = nn.ModuleList([\n",
        "            ResidualConnection(features, dropout),\n",
        "            ResidualConnection(features, dropout),\n",
        "            ResidualConnection(features, dropout)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x, src_mask):\n",
        "        # First self-attention\n",
        "        x = self.residual_connections[0](x, lambda x: self.self_attention_block1(x, x, x, src_mask))\n",
        "        # Second self-attention\n",
        "        x = self.residual_connections[1](x, lambda x: self.self_attention_block2(x, x, x, src_mask))\n",
        "        # Feed-forward\n",
        "        x = self.residual_connections[2](x, self.feed_forward_block)\n",
        "        return x"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-14T06:29:22.397338Z",
          "iopub.execute_input": "2025-08-14T06:29:22.397604Z",
          "iopub.status.idle": "2025-08-14T06:29:22.419042Z",
          "shell.execute_reply.started": "2025-08-14T06:29:22.397582Z",
          "shell.execute_reply": "2025-08-14T06:29:22.418504Z"
        },
        "id": "8-UfNsl2Wsa9"
      },
      "outputs": [],
      "execution_count": 62
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, features: int, layers: nn.ModuleList):\n",
        "    super().__init__()\n",
        "    self.layers = layers\n",
        "    self.norm = nn.LayerNorm(features)\n",
        "\n",
        "  def forward(self, x, mask):\n",
        "    for layer in self.layers:\n",
        "      x = layer(x, mask)\n",
        "    return self.norm(x)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-14T06:29:22.422685Z",
          "iopub.execute_input": "2025-08-14T06:29:22.422879Z",
          "iopub.status.idle": "2025-08-14T06:29:22.435855Z",
          "shell.execute_reply.started": "2025-08-14T06:29:22.422859Z",
          "shell.execute_reply": "2025-08-14T06:29:22.435268Z"
        },
        "id": "6IzdWwQaWsa9"
      },
      "outputs": [],
      "execution_count": 63
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "  def __init__(self, features: int, self_attention_block: MultiHeadAttentionBlock, cross_attention_block: MultiHeadAttentionBlock, feed_forward_block: FeedForwardBlock, dropout: float):\n",
        "    super().__init__()\n",
        "    self.self_attention_block = self_attention_block\n",
        "    self.cross_attention_block = cross_attention_block\n",
        "    self.feed_forward_block = feed_forward_block\n",
        "    self.residual_connections = nn.ModuleList([ResidualConnection(features, dropout) for _ in range(3)])\n",
        "\n",
        "  def forward(self, x, encoder_output, src_mask, tgt_mask):\n",
        "    x = self.residual_connections[0](x, lambda x: self.self_attention_block(x, x, x, tgt_mask))\n",
        "    x = self.residual_connections[1](x, lambda x: self.cross_attention_block(x, encoder_output, encoder_output, src_mask))\n",
        "    x = self.residual_connections[2](x, self.feed_forward_block)\n",
        "    return x"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-14T06:29:22.436562Z",
          "iopub.execute_input": "2025-08-14T06:29:22.436733Z",
          "iopub.status.idle": "2025-08-14T06:29:22.454890Z",
          "shell.execute_reply.started": "2025-08-14T06:29:22.436719Z",
          "shell.execute_reply": "2025-08-14T06:29:22.454299Z"
        },
        "id": "jnJnN6iNWsa9"
      },
      "outputs": [],
      "execution_count": 64
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, features: int, layers: nn.ModuleList):\n",
        "    super().__init__()\n",
        "    self.layers = layers\n",
        "    self.norm = nn.LayerNorm(features)\n",
        "\n",
        "  def forward(self, x, encoder_output, src_mask, tgt_mask):\n",
        "    for layer in self.layers:\n",
        "      x = layer(x, encoder_output, src_mask, tgt_mask)\n",
        "    return self.norm(x)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-14T06:29:22.455591Z",
          "iopub.execute_input": "2025-08-14T06:29:22.455842Z",
          "iopub.status.idle": "2025-08-14T06:29:22.476920Z",
          "shell.execute_reply.started": "2025-08-14T06:29:22.455821Z",
          "shell.execute_reply": "2025-08-14T06:29:22.476276Z"
        },
        "id": "SkARHM52Wsa9"
      },
      "outputs": [],
      "execution_count": 65
    },
    {
      "cell_type": "code",
      "source": [
        "class ProjectionLayer(nn.Module):\n",
        "  def __init__(self, d_model: int, vocab_size: int):\n",
        "    super().__init__()\n",
        "    self.proj = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # (batch, seq_len, d_model) --> (batch, seq_len, vocab_size)\n",
        "    return self.proj(x)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-14T06:29:22.477763Z",
          "iopub.execute_input": "2025-08-14T06:29:22.477967Z",
          "iopub.status.idle": "2025-08-14T06:29:22.494675Z",
          "shell.execute_reply.started": "2025-08-14T06:29:22.477951Z",
          "shell.execute_reply": "2025-08-14T06:29:22.494087Z"
        },
        "id": "ANjar-Q3Wsa-"
      },
      "outputs": [],
      "execution_count": 66
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "\n",
        "  def __init__(self, encoder: Encoder, decoder: Decoder, src_embed: InputEmbeddings, tgt_embed: InputEmbeddings, src_pos: PositionalEncoding, tgt_pos: PositionalEncoding, projection_layer: ProjectionLayer):\n",
        "    super().__init__()\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.src_embed = src_embed\n",
        "    self.tgt_embed = tgt_embed\n",
        "    self.src_pos = src_pos\n",
        "    self.tgt_pos = tgt_pos\n",
        "    self.projection_layer = projection_layer\n",
        "\n",
        "    d_model = src_embed.d_model\n",
        "    self.src_pos_norm = nn.LayerNorm(d_model)\n",
        "    self.tgt_pos_norm = nn.LayerNorm(d_model)\n",
        "\n",
        "  def encode(self, src, src_mask):\n",
        "    src = self.src_embed(src)\n",
        "    src = self.src_pos(src)\n",
        "    src = self.src_pos_norm(src)\n",
        "    return self.encoder(src, src_mask)\n",
        "\n",
        "  def decode(self, encoder_output, src_mask, tgt, tgt_mask):\n",
        "    tgt = self.tgt_embed(tgt)\n",
        "    tgt = self.tgt_pos(tgt)\n",
        "    tgt = self.tgt_pos_norm(tgt)\n",
        "    return self.decoder(tgt, encoder_output, src_mask, tgt_mask)\n",
        "\n",
        "  def project(self, x):\n",
        "    return self.projection_layer(x)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-14T06:29:22.495315Z",
          "iopub.execute_input": "2025-08-14T06:29:22.495546Z",
          "iopub.status.idle": "2025-08-14T06:29:22.513891Z",
          "shell.execute_reply.started": "2025-08-14T06:29:22.495521Z",
          "shell.execute_reply": "2025-08-14T06:29:22.513245Z"
        },
        "id": "PNt_ZhcHWsa-"
      },
      "outputs": [],
      "execution_count": 67
    },
    {
      "cell_type": "code",
      "source": [
        "def build_transformer(src_vocab_size: int, tgt_vocab_size: int, src_seq_len: int, tgt_seq_len: int, d_model: int=512, N: int=6, h: int=8, dropout: float=0.1, d_ff: int=2048) -> Transformer:\n",
        "    # Create the embedding layers\n",
        "    src_embed = InputEmbeddings(d_model, src_vocab_size)\n",
        "    tgt_embed = InputEmbeddings(d_model, tgt_vocab_size)\n",
        "\n",
        "    # Create the positional encoding layers\n",
        "    src_pos = PositionalEncoding(d_model, src_seq_len, dropout)\n",
        "    tgt_pos = PositionalEncoding(d_model, tgt_seq_len, dropout)\n",
        "\n",
        "    # Create the encoder blocks\n",
        "    encoder_blocks = []\n",
        "    for _ in range(N):\n",
        "        encoder_self_attention_block_1 = MultiHeadAttentionBlock(d_model, h, dropout)\n",
        "        encoder_self_attention_block_2 = MultiHeadAttentionBlock(d_model, h, dropout)\n",
        "        feed_forward_block = FeedForwardBlock(d_model, d_ff, dropout)\n",
        "        encoder_block = EncoderLayer(d_model, encoder_self_attention_block_1, encoder_self_attention_block_2, feed_forward_block, dropout)\n",
        "        encoder_blocks.append(encoder_block)\n",
        "\n",
        "    # Create the decoder blocks\n",
        "    decoder_blocks = []\n",
        "    for _ in range(N - 2):\n",
        "        decoder_self_attention_block = MultiHeadAttentionBlock(d_model, h, dropout)\n",
        "        decoder_cross_attention_block = MultiHeadAttentionBlock(d_model, h, dropout)\n",
        "        feed_forward_block = FeedForwardBlock(d_model, d_ff, dropout)\n",
        "        decoder_block = DecoderLayer(d_model, decoder_self_attention_block, decoder_cross_attention_block, feed_forward_block, dropout)\n",
        "        decoder_blocks.append(decoder_block)\n",
        "\n",
        "    # Create the encoder and decoder\n",
        "    encoder = Encoder(d_model, nn.ModuleList(encoder_blocks))\n",
        "    decoder = Decoder(d_model, nn.ModuleList(decoder_blocks))\n",
        "\n",
        "    # Create the projection layer\n",
        "    projection_layer = ProjectionLayer(d_model, tgt_vocab_size)\n",
        "\n",
        "    # Create the transformer\n",
        "    transformer = Transformer(encoder, decoder, src_embed, tgt_embed, src_pos, tgt_pos, projection_layer)\n",
        "    # weight typing\n",
        "    projection_layer.proj.weight = tgt_embed.embedding.weight\n",
        "\n",
        "    # Initialize the parameters\n",
        "    for p in transformer.parameters():\n",
        "        if p.dim() > 1:\n",
        "            nn.init.xavier_uniform_(p)\n",
        "\n",
        "    return transformer"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-14T06:29:22.514624Z",
          "iopub.execute_input": "2025-08-14T06:29:22.514885Z",
          "iopub.status.idle": "2025-08-14T06:29:22.537574Z",
          "shell.execute_reply.started": "2025-08-14T06:29:22.514869Z",
          "shell.execute_reply": "2025-08-14T06:29:22.536809Z"
        },
        "id": "Q5QfrE_uWsa-"
      },
      "outputs": [],
      "execution_count": 68
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training process"
      ],
      "metadata": {
        "id": "ocqjL4-ZsGkx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install tqdm\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-14T06:29:22.538400Z",
          "iopub.execute_input": "2025-08-14T06:29:22.538614Z",
          "iopub.status.idle": "2025-08-14T06:29:22.560640Z",
          "shell.execute_reply.started": "2025-08-14T06:29:22.538600Z",
          "shell.execute_reply": "2025-08-14T06:29:22.559996Z"
        },
        "id": "bStqHMETWsa-"
      },
      "outputs": [],
      "execution_count": 69
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tạo Dataloader, chia thành các batch để xử lý song song"
      ],
      "metadata": {
        "id": "5Ypbef3usPZz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.src = df['en_input']\n",
        "        self.tgt_in = df['vi_input']\n",
        "        self.tgt_out = df['vi_target']\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.src)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Chỉ trả về tensor, không padding\n",
        "        return {\n",
        "            'src': torch.tensor(self.src.iloc[idx], dtype=torch.long),\n",
        "            'tgt_in': torch.tensor(self.tgt_in.iloc[idx], dtype=torch.long),\n",
        "            'tgt_out': torch.tensor(self.tgt_out.iloc[idx], dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# Hàm collate_fn\n",
        "def collate_fn(batch):\n",
        "    pad_id_en = tokenizer_en.token_to_id(\"<pad>\")\n",
        "    pad_id_vi = tokenizer_vi.token_to_id(\"<pad>\")\n",
        "\n",
        "    src_batch = [item['src'] for item in batch]\n",
        "    tgt_in_batch = [item['tgt_in'] for item in batch]\n",
        "    tgt_out_batch = [item['tgt_out'] for item in batch]\n",
        "\n",
        "    # pad_sequence sẽ tự động pad đến độ dài lớn nhất trong batch\n",
        "    src_padded = pad_sequence(src_batch, batch_first=True, padding_value=pad_id_en)\n",
        "    tgt_in_padded = pad_sequence(tgt_in_batch, batch_first=True, padding_value=pad_id_vi)\n",
        "    tgt_out_padded = pad_sequence(tgt_out_batch, batch_first=True, padding_value=pad_id_vi)\n",
        "\n",
        "    return {\n",
        "        'src': src_padded,\n",
        "        'tgt_in': tgt_in_padded,\n",
        "        'tgt_out': tgt_out_padded\n",
        "    }"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-14T06:29:22.561491Z",
          "iopub.execute_input": "2025-08-14T06:29:22.561664Z",
          "iopub.status.idle": "2025-08-14T06:29:22.578515Z",
          "shell.execute_reply.started": "2025-08-14T06:29:22.561651Z",
          "shell.execute_reply": "2025-08-14T06:29:22.577778Z"
        },
        "id": "sidiclciWsa_"
      },
      "outputs": [],
      "execution_count": 70
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = TranslationDataset(train_encoded)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "test_dataset = TranslationDataset(test_encoded)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-14T06:29:22.579252Z",
          "iopub.execute_input": "2025-08-14T06:29:22.579479Z",
          "iopub.status.idle": "2025-08-14T06:29:22.599499Z",
          "shell.execute_reply.started": "2025-08-14T06:29:22.579451Z",
          "shell.execute_reply": "2025-08-14T06:29:22.598716Z"
        },
        "id": "-Wx-bTfTWsa_"
      },
      "outputs": [],
      "execution_count": 71
    },
    {
      "cell_type": "code",
      "source": [
        "# Hàm tạo mask\n",
        "def create_mask(src, tgt, pad_id=tokenizer_en.token_to_id(\"<pad>\")):\n",
        "    # src: (batch, src_len), tgt: (batch, tgt_len)\n",
        "    src_mask = (src != pad_id).unsqueeze(1).unsqueeze(2)  # (batch, 1, 1, src_len)\n",
        "    tgt_pad_mask = (tgt != pad_id).unsqueeze(1).unsqueeze(2)  # (batch, 1, 1, tgt_len)\n",
        "    tgt_len = tgt.size(1)\n",
        "    tgt_sub_mask = torch.tril(torch.ones((tgt_len, tgt_len), device=tgt.device)).bool()  # (tgt_len, tgt_len)\n",
        "    tgt_mask = tgt_pad_mask & tgt_sub_mask  # (batch, 1, tgt_len, tgt_len)\n",
        "    return src_mask, tgt_mask"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-14T06:29:22.600334Z",
          "iopub.execute_input": "2025-08-14T06:29:22.600579Z",
          "iopub.status.idle": "2025-08-14T06:29:22.615010Z",
          "shell.execute_reply.started": "2025-08-14T06:29:22.600554Z",
          "shell.execute_reply": "2025-08-14T06:29:22.614406Z"
        },
        "id": "MJc4Z_gYWsa_"
      },
      "outputs": [],
      "execution_count": 72
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hàm huấn luyện trong 1 epoch"
      ],
      "metadata": {
        "id": "S2E9y6uBsXSk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.amp import autocast, GradScaler\n",
        "scaler = GradScaler()\n",
        "\n",
        "def train_one_epoch(model, dataloader, optimizer, loss_fn, device, scheduler=None):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    progress_bar = tqdm(dataloader, desc=\"Training\", leave=False)\n",
        "\n",
        "    for batch in progress_bar:\n",
        "        src = batch['src'].to(device)\n",
        "        tgt_input = batch['tgt_in'].to(device)\n",
        "        tgt_output = batch['tgt_out'].to(device)\n",
        "\n",
        "        src_mask, tgt_mask = create_mask(src, tgt_input)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with autocast(device_type=device.type):  # mixed precision context\n",
        "            encoder_output = model.encode(src, src_mask)\n",
        "            decoder_output = model.decode(encoder_output, src_mask, tgt_input, tgt_mask)\n",
        "            output = model.project(decoder_output)\n",
        "\n",
        "            loss = loss_fn(output.reshape(-1, output.shape[-1]), tgt_output.reshape(-1))\n",
        "\n",
        "        # backward and step using scaler\n",
        "        scaler.scale(loss).backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        progress_bar.set_postfix(loss=loss.item())\n",
        "\n",
        "    return total_loss / len(dataloader)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-14T06:29:22.615840Z",
          "iopub.execute_input": "2025-08-14T06:29:22.616115Z",
          "iopub.status.idle": "2025-08-14T06:29:22.732770Z",
          "shell.execute_reply.started": "2025-08-14T06:29:22.616082Z",
          "shell.execute_reply": "2025-08-14T06:29:22.732063Z"
        },
        "id": "0TOTzyUpWsa_"
      },
      "outputs": [],
      "execution_count": 73
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hàm ước tính loss trong quá trình training"
      ],
      "metadata": {
        "id": "DGkCg2e4sa5k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def evaluate_one_epoch(model, dataloader, loss_fn, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "\n",
        "    progress_bar = tqdm(dataloader, desc=\"Evaluating\", leave=False)\n",
        "\n",
        "    for batch in progress_bar:\n",
        "        src = batch['src'].to(device)\n",
        "        tgt_input = batch['tgt_in'].to(device)\n",
        "        tgt_output = batch['tgt_out'].to(device)\n",
        "\n",
        "        src_mask, tgt_mask = create_mask(src, tgt_input)\n",
        "\n",
        "        encoder_output = model.encode(src, src_mask)\n",
        "        decoder_output = model.decode(encoder_output, src_mask, tgt_input, tgt_mask)\n",
        "        output = model.project(decoder_output)\n",
        "\n",
        "        loss = loss_fn(output.reshape(-1, output.shape[-1]), tgt_output.reshape(-1))\n",
        "        total_loss += loss.item()\n",
        "        progress_bar.set_postfix(val_loss=loss.item())\n",
        "\n",
        "    return total_loss / len(dataloader)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-14T06:29:22.733667Z",
          "iopub.execute_input": "2025-08-14T06:29:22.733932Z",
          "iopub.status.idle": "2025-08-14T06:29:22.751434Z",
          "shell.execute_reply.started": "2025-08-14T06:29:22.733909Z",
          "shell.execute_reply": "2025-08-14T06:29:22.750688Z"
        },
        "id": "zZdxm3iuWsbA"
      },
      "outputs": [],
      "execution_count": 74
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Warm up + Inverse Square Root learning rate scheduler"
      ],
      "metadata": {
        "id": "f4wJM4OssfR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WarmupInverseSquareRootScheduler:\n",
        "    def __init__(self, optimizer, d_model, warmup_steps):\n",
        "        self.optimizer = optimizer\n",
        "        self.warmup_steps = warmup_steps\n",
        "        self.d_model = d_model\n",
        "        self.step_num = 0\n",
        "\n",
        "    def step(self):\n",
        "        self.step_num += 1\n",
        "        lr = self._get_lr()\n",
        "        for param_group in self.optimizer.param_groups:\n",
        "            param_group['lr'] = lr\n",
        "\n",
        "    def _get_lr(self):\n",
        "        arg1 = self.step_num ** (-0.5)\n",
        "        arg2 = self.step_num * (self.warmup_steps ** (-1.5))\n",
        "        return (self.d_model ** -0.5) * min(arg1, arg2)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-14T06:29:22.752138Z",
          "iopub.execute_input": "2025-08-14T06:29:22.752402Z",
          "iopub.status.idle": "2025-08-14T06:29:22.771779Z",
          "shell.execute_reply.started": "2025-08-14T06:29:22.752384Z",
          "shell.execute_reply": "2025-08-14T06:29:22.771051Z"
        },
        "id": "xVjtIO-1WsbA"
      },
      "outputs": [],
      "execution_count": 75
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hàm Beam Search"
      ],
      "metadata": {
        "id": "3OMQtNoosnPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def causal_mask(size):\n",
        "    \"\"\"\n",
        "    Tạo causal mask: chỉ cho phép mỗi vị trí nhìn thấy các token trước đó (kể cả chính nó).\n",
        "    Output shape: (1, 1, size, size)\n",
        "    \"\"\"\n",
        "    return torch.tril(torch.ones(size, size)).unsqueeze(0).unsqueeze(1)  # (1, 1, size, size)\n",
        "\n",
        "def beam_search_decode_batch_parallel(\n",
        "    model, src, src_mask, tokenizer_vi, max_len, device, beam_size=4, alpha=0.6\n",
        "):\n",
        "    def get_token_id(tok, fallback=None):\n",
        "        tid = tokenizer_vi.token_to_id(tok)\n",
        "        if tid is None and fallback is not None:\n",
        "            tid = tokenizer_vi.token_to_id(fallback)\n",
        "        return tid\n",
        "\n",
        "    with torch.no_grad():\n",
        "        batch_size = src.size(0)\n",
        "\n",
        "        sos_id = get_token_id(\"<s>\", \"[SOS]\")\n",
        "        eos_id = get_token_id(\"</s>\", \"[EOS]\")\n",
        "        pad_id = get_token_id(\"<pad>\", \"[PAD]\")\n",
        "\n",
        "        if sos_id is None or eos_id is None or pad_id is None:\n",
        "            raise ValueError(f\"Special tokens missing: sos={sos_id}, eos={eos_id}, pad={pad_id}\")\n",
        "\n",
        "        def length_penalty_fn(length, alpha):\n",
        "            return ((5.0 + length) ** alpha) / ((5.0 + 1.0) ** alpha)\n",
        "\n",
        "        # Encode input\n",
        "        memory = model.encode(src, src_mask)\n",
        "        memory = memory.repeat_interleave(beam_size, dim=0)\n",
        "        src_mask = src_mask.repeat_interleave(beam_size, dim=0)\n",
        "\n",
        "        seqs = torch.full((batch_size * beam_size, 1), sos_id, dtype=torch.long, device=device)\n",
        "        scores = torch.zeros(batch_size * beam_size, device=device)\n",
        "        finished_flags = torch.zeros(batch_size * beam_size, dtype=torch.bool, device=device)\n",
        "\n",
        "        for step in range(1, max_len):\n",
        "            tgt_mask = causal_mask(seqs.size(1)).to(device)\n",
        "            dec_out = model.decode(memory, src_mask, seqs, tgt_mask)\n",
        "            logits = model.project(dec_out[:, -1, :])\n",
        "            log_probs = torch.log_softmax(logits, dim=-1)\n",
        "\n",
        "            # Beam đã kết thúc chỉ sinh <pad>\n",
        "            log_probs[finished_flags] = -1e9\n",
        "            log_probs[finished_flags, pad_id] = 0\n",
        "\n",
        "            next_scores, next_tokens = torch.topk(log_probs, beam_size, dim=-1)\n",
        "\n",
        "            # Reshape để chọn top beam cho batch\n",
        "            next_scores = next_scores.view(batch_size, beam_size, beam_size)\n",
        "            next_tokens = next_tokens.view(batch_size, beam_size, beam_size)\n",
        "\n",
        "            # Tính total score với length penalty sớm\n",
        "            total_scores = scores.view(batch_size, beam_size, 1) + next_scores\n",
        "            lp = length_penalty_fn(step + 1, alpha)\n",
        "            total_scores = total_scores / lp\n",
        "\n",
        "            # Chọn top beam\n",
        "            top_scores, top_indices = torch.topk(total_scores.view(batch_size, -1), beam_size, dim=-1)\n",
        "            beam_indices = top_indices // beam_size\n",
        "            token_indices = top_indices % beam_size\n",
        "\n",
        "            # Vector hóa update sequences\n",
        "            old_beam_ids = (beam_indices + torch.arange(batch_size, device=device).unsqueeze(1) * beam_size).view(-1)\n",
        "            chosen_tokens = next_tokens[torch.arange(batch_size, device=device).unsqueeze(1), beam_indices, token_indices].view(-1)\n",
        "\n",
        "            seqs = torch.cat([seqs[old_beam_ids], chosen_tokens.unsqueeze(1)], dim=-1)\n",
        "            scores = top_scores.view(-1)\n",
        "\n",
        "            # Cập nhật finished flags\n",
        "            finished_flags = finished_flags[old_beam_ids] | (chosen_tokens == eos_id)\n",
        "\n",
        "            if finished_flags.all():\n",
        "                break\n",
        "\n",
        "        # Chọn best beam cuối cùng\n",
        "        final_seqs = []\n",
        "        for b in range(batch_size):\n",
        "            start = b * beam_size\n",
        "            end = start + beam_size\n",
        "            cand_scores = scores[start:end]\n",
        "            cand_seqs = seqs[start:end]\n",
        "            lengths = torch.tensor([len(s) for s in cand_seqs], dtype=torch.float, device=device)\n",
        "            lp = length_penalty_fn(lengths, alpha)\n",
        "            best_idx = torch.argmax(cand_scores / lp).item()\n",
        "            final_seqs.append(cand_seqs[best_idx])\n",
        "\n",
        "        # Pad output\n",
        "        max_len_final = max(len(s) for s in final_seqs)\n",
        "        padded = torch.full((batch_size, max_len_final), pad_id, dtype=torch.long, device=device)\n",
        "        for i, seq in enumerate(final_seqs):\n",
        "            padded[i, :len(seq)] = seq\n",
        "\n",
        "        return padded"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-14T06:29:27.685069Z",
          "iopub.execute_input": "2025-08-14T06:29:27.685418Z",
          "iopub.status.idle": "2025-08-14T06:29:27.699997Z",
          "shell.execute_reply.started": "2025-08-14T06:29:27.685400Z",
          "shell.execute_reply": "2025-08-14T06:29:27.699123Z"
        },
        "id": "pzAGT2TZWsbA"
      },
      "outputs": [],
      "execution_count": 76
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hàm ước tính BLEU trên tập dữ liệu"
      ],
      "metadata": {
        "id": "qviZ8n0GssPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
        "\n",
        "def evaluate_bleu(model, dataloader, tokenizer_en, tokenizer_vi, device, max_len=128):\n",
        "    model.eval()\n",
        "    references = []\n",
        "    hypotheses = []\n",
        "\n",
        "    smoothie = SmoothingFunction().method4\n",
        "\n",
        "    sos_id = tokenizer_vi.token_to_id(\"[SOS]\") or tokenizer_vi.token_to_id(\"<s>\")\n",
        "    eos_id = tokenizer_vi.token_to_id(\"[EOS]\") or tokenizer_vi.token_to_id(\"</s>\")\n",
        "    pad_id = tokenizer_vi.token_to_id(\"<pad>\")\n",
        "    pad_src_id = tokenizer_en.token_to_id(\"<pad>\")\n",
        "\n",
        "    for batch in tqdm(dataloader, desc=\"Evaluating BLEU\"):\n",
        "        src = batch['src'].to(device)\n",
        "        tgt_input = batch['tgt_in'].to(device)\n",
        "        tgt_output = batch['tgt_out'].to(device)\n",
        "\n",
        "        src_mask = (src != pad_src_id).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        pred_ids_batch = beam_search_decode_batch_parallel(model, src, src_mask, tokenizer_vi, max_len, device, beam_size=4)\n",
        "\n",
        "        for pred_ids, ref_ids in zip(pred_ids_batch, tgt_output):\n",
        "            pred_tokens = [\n",
        "                tokenizer_vi.id_to_token(id.item())\n",
        "                for id in pred_ids\n",
        "                if id.item() not in {sos_id, eos_id, pad_id}\n",
        "            ]\n",
        "\n",
        "            ref_tokens = [\n",
        "                tokenizer_vi.id_to_token(id.item())\n",
        "                for id in ref_ids\n",
        "                if id.item() not in {sos_id, eos_id, pad_id}\n",
        "            ]\n",
        "\n",
        "            hypotheses.append(pred_tokens)\n",
        "            references.append([ref_tokens])  # each reference must be a list of lists\n",
        "\n",
        "    bleu = corpus_bleu(references, hypotheses, smoothing_function=smoothie)\n",
        "\n",
        "    print(f\"BLEU score (nltk): {bleu * 100:.2f}\")\n",
        "    return bleu"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-14T06:29:27.700802Z",
          "iopub.execute_input": "2025-08-14T06:29:27.701049Z",
          "iopub.status.idle": "2025-08-14T06:29:28.624122Z",
          "shell.execute_reply.started": "2025-08-14T06:29:27.701034Z",
          "shell.execute_reply": "2025-08-14T06:29:28.623511Z"
        },
        "id": "BUEHevhhWsbB"
      },
      "outputs": [],
      "execution_count": 77
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load lại model với trọng số đã huấn luyện được lưu trong tệp 're_transformer_best.pth'"
      ],
      "metadata": {
        "id": "dWqlBzuBsv2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "src_vocab_size = tokenizer_en.get_vocab_size()\n",
        "tgt_vocab_size = tokenizer_vi.get_vocab_size()\n",
        "\n",
        "# Load lại model\n",
        "model = build_transformer(\n",
        "    src_vocab_size=src_vocab_size,\n",
        "    tgt_vocab_size=tgt_vocab_size,\n",
        "    src_seq_len=256,\n",
        "    tgt_seq_len=256,\n",
        "    d_model=512,\n",
        "    N=6,\n",
        "    h=8,\n",
        "    dropout=0.1,\n",
        "    d_ff=1024\n",
        ").to(device)\n",
        "\n",
        "checkpoint_path = '/content/drive/MyDrive/Released Corpus/re_transformer_best.pth'\n",
        "model.load_state_dict(torch.load(checkpoint_path))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-14T06:29:28.624865Z",
          "iopub.execute_input": "2025-08-14T06:29:28.625069Z",
          "iopub.status.idle": "2025-08-14T06:29:32.093732Z",
          "shell.execute_reply.started": "2025-08-14T06:29:28.625052Z",
          "shell.execute_reply": "2025-08-14T06:29:32.092989Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0uhHeWkWsbB",
        "outputId": "a3f1fa5d-251f-4db1-a6ac-4c9081b16aab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "execution_count": 78
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Kết quả BLEU trên tập test : 57.39"
      ],
      "metadata": {
        "id": "Hx-btOs0s6xL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_bleu(model, test_dataloader, tokenizer_en, tokenizer_vi, device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-08-14T09:22:36.085Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goGQQ5S6WsbC",
        "outputId": "07c9067a-a8b8-4b34-e936-5bc2740a5b84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating BLEU: 100%|██████████| 94/94 [11:04<00:00,  7.07s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU score (nltk): 57.39\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5738936505674651"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "execution_count": 79
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hàm dịch câu tiếng Anh sang tiếng Việt"
      ],
      "metadata": {
        "id": "I5YmJ4I0s_8r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_to_vietnamese(sentence_en: str) -> str:\n",
        "    model.eval()\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    # Tiền xử lý tiếng Anh\n",
        "    src_text = english_preprocessing(sentence_en)\n",
        "    src_ids = tokenizer_en.encode(src_text).ids\n",
        "    src_ids = [tokenizer_en.token_to_id(\"<s>\")] + src_ids + [tokenizer_en.token_to_id(\"</s>\")]\n",
        "\n",
        "    src_tensor = torch.tensor(src_ids, dtype=torch.long).unsqueeze(0).to(device)\n",
        "\n",
        "    pad_id = tokenizer_en.token_to_id(\"<pad>\")\n",
        "    assert pad_id is not None, \"Tokenizer English chưa có token <pad>\"\n",
        "    src_mask = (src_tensor != pad_id).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pred_ids = beam_search_decode_batch_parallel(\n",
        "            model, src_tensor, src_mask, tokenizer_vi,\n",
        "            max_len=128, device=device, beam_size=4, alpha=0.6\n",
        "        )[0]\n",
        "\n",
        "    pred_ids = pred_ids.cpu().numpy()\n",
        "\n",
        "    # Dùng decode của tokenizer để ghép subword đúng chuẩn\n",
        "    return tokenizer_vi.decode(pred_ids, skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "DVYyYnEnhndm"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code để chạy dịch máy trên tập test 3000 câu tiếng Anh\n",
        "\n",
        "Kết quả được lưu trong tệp Re-transformer-test-translation.csv"
      ],
      "metadata": {
        "id": "OyuB6YD9tDsD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "vi_output = []\n",
        "\n",
        "# Dịch toàn bộ 3000 câu tiếng Anh\n",
        "for sentence in tqdm.tqdm(test['en'], desc=\"Translating test set\"):\n",
        "    translation = translate_to_vietnamese(sentence)\n",
        "    vi_output.append(translation)\n",
        "\n",
        "# Tạo dataframe mới\n",
        "df_result = pd.DataFrame({\n",
        "    'en': test['en'],          # câu tiếng Anh gốc\n",
        "    'vi_output': vi_output,    # câu dịch từ model\n",
        "    'vi_truth': test['vi']     # câu ground truth\n",
        "})\n",
        "\n",
        "# Lưu vào CSV\n",
        "df_result.to_csv(\"Re-transformer-test-translation.csv\", index=False, encoding='utf-8-sig')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_lJYw9Mhp43",
        "outputId": "15f956b5-52c3-4257-fe01-0056f81a1d01"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Translating test set: 100%|██████████| 3000/3000 [12:01<00:00,  4.16it/s]\n"
          ]
        }
      ]
    }
  ]
}